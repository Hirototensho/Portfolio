[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science Portfolio",
    "section": "",
    "text": "Readme\nここに要約版の目次やリンクを置きます。",
    "crumbs": [
      "Readme"
    ]
  },
  {
    "objectID": "01-typeII-tobit.html",
    "href": "01-typeII-tobit.html",
    "title": "1  タイプIIトービットモデル",
    "section": "",
    "text": "1.1 要約",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>タイプIIトービットモデル</span>"
    ]
  },
  {
    "objectID": "01-typeII-tobit.html#要約",
    "href": "01-typeII-tobit.html#要約",
    "title": "1  タイプIIトービットモデル",
    "section": "",
    "text": "賃金やECサイトでの購買金額のように、特定の回答者（e.g. 働いている人, ECサイトの利用者）しか観測できないデータを被説明変数とする場合に使える手法です\n被説明変数を観測できている人だけを対象として分析を行うと、セレクションバイアスが生じます\nタイプIIトービットモデルを用いることで、セレクションバイアスを避けながら分析を行うことができます",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>タイプIIトービットモデル</span>"
    ]
  },
  {
    "objectID": "01-typeII-tobit.html#タイプiiトービットモデルの概要",
    "href": "01-typeII-tobit.html#タイプiiトービットモデルの概要",
    "title": "1  タイプIIトービットモデル",
    "section": "1.2 タイプIIトービットモデルの概要",
    "text": "1.2 タイプIIトービットモデルの概要\n　個人 \\(i\\) の賃金を \\(W_i\\) として \\(\\log W_i = \\boldsymbol{X}_i^\\mathsf{T}\\boldsymbol{\\beta} + \\epsilon_{2i}\\) で定まる回帰モデルを推定する問題を考えます。これは労働経済学ではミンサー型賃金関数と呼ばれ、年齢と所得の関係を調べる賃金プロファイルや、教育年数が所得に与える効果を調べるために用いられます(大森 & 永瀬, 2021; 川口, 2017)。賃金関数の推定に当たっては、賃金 \\(W_i\\) が就業者についてしか観測することができないことが問題となります（図 1.1）。\n　このような状況は、就労状況に関する社会調査で頻繁に見られます。例えばリクルートワークス研究所が実施している「全国就業実態パネル調査」でも、今現在働いている回答者は仕事からの年収について質問される一方で、今現在働いていない回答者は質問されない（設問の対象から外れる）ことになっています。\n\n\n\n\n\n\n\n\n図 1.1: 一部の回答者の賃金が観測できない状況\n\n\n\n\n\n　働いていない回答者からすれば、仕事からの年収について質問されても答えようがないので、欠測値になるのは仕方のないことです。しかし、通常の回帰分析は被説明変数に欠測値がないことが前提になっているので、何かしらの対処が必要になります。\n　欠測値に対する簡単な対処法として、賃金 \\(W_i\\) が観測されているデータだけを使って分析すること（完全ケース解析）が考えられますが、就業者と非就業者の属性に系統的な違い（例：女性や高齢者の非就業率が高い）があるなら、推定結果にバイアス（選択バイアス）が生じる可能性があります。また、非就業者について欠測値を0で埋めること（定数代入）も適切ではありません。なぜなら、現在働いていない人でも働けば一定額の賃金が得られるはずだからです(末石, 2015, pp. 111–113)。\n　このような課題に対して、完全ケース解析や定数代入を避けて分析を実施する方法の1つがタイプIIトービットモデルです。タイプIIトービットモデルでは、賃金が観測されるかどうか（≒ その回答者が働いているかどうか）を予測するプロビットモデルと、賃金を予測する線形モデルを組み合わせることで、選択バイアスを補正します(図 1.2)。タイプIIトービットモデルの推定方法としては、Heckman の2段階推定と最尤法が知られていますが、どちらもsampleSelection パッケージの heckit() 関数として実装されています。\n\n\n\n\n\n\n\n\n図 1.2: タイプIIトービットモデルの模式図",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>タイプIIトービットモデル</span>"
    ]
  },
  {
    "objectID": "01-typeII-tobit.html#heckman-の2段階推定",
    "href": "01-typeII-tobit.html#heckman-の2段階推定",
    "title": "1  タイプIIトービットモデル",
    "section": "1.3 Heckman の2段階推定",
    "text": "1.3 Heckman の2段階推定\n　ここではタイプIIトービットモデルの推定法のうち、より簡単な Heckman の2段階推定について説明します。Heckman の2段階推定は、(1) 賃金 \\(W_i\\) が観測されるかどうかを予測するプロビットモデル（就業決定関数）、(2) 賃金を予測する線形モデル（賃金関数）を、次のような手順で組み合わせます。\n　まず、賃金が観測されていれば1、観測されていなければ0となるダミー変数 \\(D_i\\) を被説明変数として使い、 \\(\\boldsymbol{Z}_i\\) を説明変数とする、次のプロビットモデルを推定します。\n\\[\n\\large\n\\begin{equation}\n\\begin{aligned}\n\\Phi(D_i) &= \\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma} + \\epsilon_{1i}\n\\end{aligned}\n\\end{equation}\n\\tag{1.1}\\]\n次に、推定されたプロビットモデルから \\(\\lambda(\\boldsymbol{Z}_i^\\mathsf{T} \\boldsymbol{\\gamma}) = \\phi(\\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma}) / \\Phi(\\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma})\\) として定義される逆ミルズ比を推定します。最後に、逆ミルズ比を説明変数に加えた次のモデルを最小二乗法で推定することで、セレクションバイアスが補正された回帰係数 \\(\\boldsymbol{\\beta}\\) の推定値を得ることができます。\n\\[\n\\large\n\\begin{equation}\n\\begin{aligned}\n\\log W_i &= \\boldsymbol{X}_i^\\mathsf{T}\\boldsymbol{\\beta}\n+ \\sigma_{12}\\lambda(\\boldsymbol{Z}_i^\\mathsf{T} \\boldsymbol{\\gamma})\n+ \\epsilon_{2i}\n\\end{aligned}\n\\end{equation}\n\\tag{1.2}\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>タイプIIトービットモデル</span>"
    ]
  },
  {
    "objectID": "01-typeII-tobit.html#使用上の注意点",
    "href": "01-typeII-tobit.html#使用上の注意点",
    "title": "1  タイプIIトービットモデル",
    "section": "1.4 使用上の注意点",
    "text": "1.4 使用上の注意点\nタイプIIトービットモデルの使用にあたり、次の2点に注意が必要です。\n\nプロビットモデルの説明変数 \\(\\boldsymbol{Z}_i\\) には、線形モデルの説明変数 \\(\\boldsymbol{X}_i\\) に含まれていない変数を、少なくとも追加する必要がある\n\n具体的には、線形モデルの説明変数 \\(\\boldsymbol{X}_i\\) には教育年数と年齢を使い、プロビットモデルの説明変数 \\(\\boldsymbol{Z}_i\\) には教育年数と年齢に加えて子どもの人数を使う、といった配慮が必要です。\n\n説明変数 \\(\\boldsymbol{Z}_i, \\boldsymbol{X}_i\\) の欠測値には、タイプIIトービットモデルだけでは対応できない\n\n職場の業種や現職の勤続年数、職種、肩書など、賃金以外にも非就業者については観測できない変数は数多くあります。しかし、タイプIIトービットモデルで対応できるのは被説明変数の欠測だけなので、就業者と非就業者の両方で観測できる説明変数だけを使うか、他の方法で補完するといった対応が必要です",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>タイプIIトービットモデル</span>"
    ]
  },
  {
    "objectID": "01-typeII-tobit.html#rによる実装",
    "href": "01-typeII-tobit.html#rによる実装",
    "title": "1  タイプIIトービットモデル",
    "section": "1.5 Rによる実装",
    "text": "1.5 Rによる実装\n\nExample 1.1 (Heckman の2段階推定法) ここでは sampleSelection パッケージの Mroz87データを例にHeckman の2段階推定法を実装します。まずはサンプルデータを読み込みます。\ndata(\"Mroz87\", package = \"sampleSelection\")\nMroz87 |&gt; mutate()\n\nMroz87 &lt;- Mroz87 |&gt; \n  naniar::replace_with_na(replace = list(wage = 0)) |&gt; \n  mutate(lwage = log(wage))\n\nMroz87 |&gt; nrow()\n#&gt; [1] 753\n\n# 労働参加 lfp = 0 の回答者は全て lwage が観測されています。\nMroz87 |&gt; mutate(miss_lwage = is.na(lwage)) |&gt; \n  janitor::tabyl(lfp, miss_lwage)\n#&gt;  inlf FALSE TRUE\n#&gt;     0     0  325\n#&gt;     1   428    0\n次に sampleSelection::heckit() 関数でタイプIIトービットモデルを推定します。\nfit_heckit &lt;- sampleSelection::heckit(\n  selection = lfp ~ educ + exper + I(exper^2) + nwifeinc + age + kids5 + kids618, # 就業決定関数\n  outcome =  lwage ~ educ + exper + I(exper^2),                                   # 賃金関数\n  data = Mroz87,\n  method = \"2step\"\n)\nsummary(fit_heckit)\n#&gt; --------------------------------------------\n#&gt; Tobit 2 model (sample selection model)\n#&gt; 2-step Heckman / heckit estimation\n#&gt; 753 observations (325 censored and 428 observed)\n#&gt; 15 free parameters (df = 739)\n#&gt; Probit selection equation:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.270077   0.508593   0.531  0.59556    \n#&gt; educ         0.130905   0.025254   5.183 2.81e-07 ***\n#&gt; exper        0.123348   0.018716   6.590 8.34e-11 ***\n#&gt; I(exper^2)  -0.001887   0.000600  -3.145  0.00173 ** \n#&gt; nwifeinc    -0.012024   0.004840  -2.484  0.01320 *  \n#&gt; age         -0.052853   0.008477  -6.235 7.61e-10 ***\n#&gt; kids5       -0.868328   0.118522  -7.326 6.21e-13 ***\n#&gt; kids618      0.036005   0.043477   0.828  0.40786    \n#&gt; Outcome equation:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -0.5781032  0.3050062  -1.895  0.05843 .  \n#&gt; educ         0.1090655  0.0155230   7.026 4.83e-12 ***\n#&gt; exper        0.0438873  0.0162611   2.699  0.00712 ** \n#&gt; I(exper^2)  -0.0008591  0.0004389  -1.957  0.05068 .  \n#&gt; Multiple R-Squared:0.1569,   Adjusted R-Squared:0.149\n#&gt;    Error terms:\n#&gt;               Estimate Std. Error t value Pr(&gt;|t|)\n#&gt; invMillsRatio  0.03226    0.13362   0.241    0.809\n#&gt; sigma          0.66363         NA      NA       NA\n#&gt; rho            0.04861         NA      NA       NA\n#&gt; --------------------------------------------\n　この結果は、春山(2023)がコードを公開している Heckit() 関数を適用した結果と一致していました。ちなみに、sampleSelection::heckit(method = \"2step\") の結果に broom::tidy() を使うときは broom::tidy(fit_heckit$lm) で賃金関数の推定値を、broom::tidy(fit_heckit$probit) で就業決定関数の推定値を表示できるほか、texreg::screenreg() 関数にも対応しています。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>タイプIIトービットモデル</span>"
    ]
  },
  {
    "objectID": "01-typeII-tobit.html#タイプiiトービットモデルの限界効果",
    "href": "01-typeII-tobit.html#タイプiiトービットモデルの限界効果",
    "title": "1  タイプIIトービットモデル",
    "section": "1.6 タイプIIトービットモデルの限界効果",
    "text": "1.6 タイプIIトービットモデルの限界効果\n　計量経済学の実証論文では、ロジスティック回帰やプロビットモデルの推定結果を限界効果（marginal effect）に変換してから掲載することがよく行われます。限界効果とは、ある説明変数 \\(\\boldsymbol{x}_j\\) が僅かに変化したときに、被説明変数や予測確率がどの程度増減するかを表すもので、回帰式を説明変数 \\(\\boldsymbol{x}_{ij}\\) で偏微分したものとして定義されます。\n　タイプIIトービットモデルについても、次式によって限界効果を計算できることが知られています(Hoffmann & Kassouf, 2005; ダハナ & 勝又, 2023, pp. 139–140)。\n\\[\n\\large\n\\begin{equation}\n\\begin{aligned}\nME(x_{ij}) &= \\frac{\\partial}{\\partial x_{i, j}}\\log E[W_i]\n= \\underbrace{\n\\beta_j - \\gamma_j \\sigma_{12} \\delta_i}_{e_I}\n+ \\underbrace{\n\\gamma_j \\lambda(\\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma})\n}_{e_{II}}\\\\\n\\delta_i &= \\lambda(\\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma})\n[\\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma}\n+ \\lambda(\\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma})]\n\\end{aligned}\n\\end{equation}\n\\tag{1.3}\\]\n式 1.3 の限界効果には、条件付き限界効果 \\(e_I\\)、間接効果 \\(e_{II}\\)、条件なしの限界効果 \\(ME(x_{ij})\\) の3通りに分解できるという特徴があり、それぞれの項には次のような意味があります(Hoffmann & Kassouf, 2005)。\n\n\\(e_I\\) 条件付き限界効果（conditional marginal effect）： 説明変数 \\(\\boldsymbol{x}_j\\) の変化が就業者の賃金に与える効果を表す\n\\(e_{II}\\) 間接効果：説明変数 \\(\\boldsymbol{x}_j\\) の変化が、就業率の変化を通じて間接的に賃金を変化させる効果\n\\(ME(x_{ij})\\) 条件なしの限界効果（unconditional marginal effect）：説明変数 \\(\\boldsymbol{x}_j\\) の変化が就業者と非就業者の全体の賃金に与える効果を表す\n\n　例えば Hoffmann, Kassouf(2005, p. 12)は、実証分析に 式 1.3 の分解を利用することで、ブラジルの女性の教育年数が1年伸びることが、勤労女性の収入を11.6%上昇させると同時に、女性の労働市場参加率を5.2%増加させることで、女性全体の所得を17.4％増加させる効果を持つと報告しています。　　 　このように、教育年数が収入に与える効果をより豊かな洞察をもたらす形で提示できることは、タイプIIトービットモデルを用いる利点の1つだと言えるでしょう。\n\nExample 1.2 (タイプIIトービットモデルの限界効果) ここではタイプIIトービットモデルの限界効果をRで実装します。ダハナ, 勝又(2023, pp. 139–140)と Hoffmann, Kassouf(2005)、そして heckitmfxパッケージの heckitmfx::heckitmfx_log() 関数の実装を参考に、式 1.3 の限界効果をRの関数として実装します。\n\n\nheckitmfx.R\n\n# メインの関数から呼び出されて、限界効果を推定する関数 ------------------------------------------------------------\nheckitmfx_compute &lt;- function(\n    gamma, beta, betalambda, Z, ...\n    # type = c(\"unconditional\", \"conditional\", \"selection\")\n){\n  # 就業決定関数の予測値と逆ミルズ比の計算 ---------------------------------\n  alpha &lt;- Z %*% gamma\n  lambda &lt;- dnorm(alpha) / pnorm(alpha)\n  delta &lt;- lambda * (lambda + alpha)\n  \n  # 限界効果の各項の計算 ---------------------\n  selection &lt;- gamma[-1] * mean(lambda)\n  ei_2 &lt;- gamma[-1] * betalambda * mean(delta)\n  \n  # ダミー変数用の処理 --------------\n  dummy_vars &lt;- apply(Z[, -1], FUN = is_dummy, MARGIN = 2)\n  \n  if(sum(dummy_vars) &gt;= 1){\n    terms_for_dummy_vars &lt;- names(dummy_vars[dummy_vars]) |&gt;\n      terms_for_dummy(Z, gamma, betalambda)\n    \n    # ダミー変数についての推定値に置換\n    ei_2[dummy_vars] &lt;- terms_for_dummy_vars[1, ]\n    selection[dummy_vars] &lt;- terms_for_dummy_vars[2, ]\n  }\n  \n  # 回帰係数と限界効果の各項をデータフレームにまとめます。\n  est &lt;- merge(\n    data.frame(beta = beta[-1]), \n    data.frame(gamma = gamma[-1]), \n    by = \"row.names\", all = TRUE\n    ) |&gt; \n    rename(term = \"Row.names\") |&gt; \n    full_join(tibble::tibble(ei_2, term = names(ei_2)), by = join_by(term)) |&gt; \n    full_join(tibble::tibble(selection, term = names(selection)), by = join_by(term))\n  \n  est[is.na(est)] &lt;- 0\n  \n  # 限界効果の推定\n  res &lt;- est |&gt; \n    mutate(\n      term = as.character(term),\n      conditional = beta - ei_2,\n      unconditional = conditional + selection\n    ) |&gt; \n    select(term, unconditional, conditional, selection, beta, gamma)\n  # 結果の出力 ---------------------------------\n  \n  return(res)\n}\n\n次に、Hoffmann, Kassouf(2005)に基づいて説明変数 \\(\\boldsymbol{x}_j\\) がダミー変数である場合の処理を実装します。\n\n\nheckitmfx.R\n\n# ダミー変数を判定する関数\nis_dummy &lt;- function(x, unique_value = c(0, 1), na.rm = FALSE) {\n  if(na.rm) x &lt;- na.omit(x)\n  res &lt;- checkmate::test_set_equal(x = x, y = unique_value)\n  return(res)\n}\n\n# ダミー変数に関する間接効果の計算\nterms_for_dummy &lt;- Vectorize(function(var_name, Z, gamma, betalambda){\n  fun_inv_mills &lt;- \\(x) dnorm(x) / pnorm(x)\n  \n  z_1 &lt;- z_0 &lt;- colMeans(Z)\n  z_1[var_name] &lt;- 1\n  z_0[var_name] &lt;- 0\n  \n  delta_lambda &lt;- betalambda * as.vector(fun_inv_mills(z_1 %*% gamma) - fun_inv_mills(z_0 %*% gamma))\n  delta_log_phi &lt;- as.vector(pnorm(z_1 %*% gamma, log.p = TRUE) - pnorm(z_0 %*% gamma, log.p = TRUE))\n  \n  res &lt;- rbind(delta_lambda, delta_log_phi) \n  return(res)\n}, vectorize.args = \"var_name\")\n\n最後に、限界効果を推定するメインの関数を実装します。\n\n\nheckitmfx.R\n\n# モデルオブジェクトから限界効果を推定するメインの関数 ------------------------------------------------------------\nheckitmfx &lt;- function(model, newdata = NULL, .params = NULL, ...){\n  # 回帰係数の抽出 ---------------------------------\n  if(is.null(.params)){\n    coef_all &lt;- coef(model) # 全ての回帰係数を取得  \n  }else{\n    # デルタ法の実装に使うための、回帰係数を任意の値で上書きする機能\n    coef_all &lt;- .params # 引数 .params が指定されていた場合は .params で上書きする\n  }\n  \n  # 全ての説明変数の名前を抽出\n  all_vars &lt;- names(coef_all) |&gt; unique() %&gt;% \n    subset(!(. %in% c(\"(Intercept)\", \"invMillsRatio\", \"sigma\", \"rho\")))\n  \n  # 賃金関数の回帰係数が始まる位置を特定する\n  start_beta &lt;- which(names(coef_all) == \"(Intercept)\")[2]\n  \n  gamma &lt;- coef_all[1:(start_beta - 1)] # 就業決定関数の回帰係数\n  \n  # 賃金関数の回帰係数\n  beta &lt;- coef_all[start_beta:length(coef_all)] %&gt;%\n    subset(!(names(.) %in% c(\"invMillsRatio\", \"sigma\", \"rho\")))\n  \n  betalambda &lt;- coef_all %&gt;% subset((names(.) %in% c(\"sigma\", \"rho\"))) |&gt; prod()\n  \n  # 就業決定関数の計画行列の抽出 ---------------------------------\n  if(model$method == \"2step\"){\n    Z &lt;- model.matrix(model$probit, data = newdata)\n    colnames(Z) &lt;- str_remove(colnames(Z), \"XS\")\n  }else{\n    if(model$method == \"ml\"){\n      Z &lt;- model.matrix(model$termsS, data = newdata)\n    }\n  }\n  # 限界効果の推定\n  res &lt;- heckitmfx_compute(\n    gamma = gamma,\n    beta = beta,\n    betalambda = betalambda,\n    Z = Z\n  )\n  return(res)\n}\n\n　例題 1.1 で推定したモデル（fit_heckit）に対して heckitmfx() を実行すると、次のような結果が得られます。\n#| paged-print: false\n# 2段階推定に基づく結果\nheckitmfx(fit_heckit) |&gt; \n  mutate(across(where(is.numeric), .fns = \\(x) round(x, 5)))\n#&gt;         term unconditional conditional selection     beta    gamma\n#&gt; 1        age      -0.03854     0.00095  -0.03950  0.00000 -0.05285\n#&gt; 2       educ       0.20453     0.10670   0.09782  0.10907  0.13090\n#&gt; 3      exper       0.13384     0.04166   0.09217  0.04389  0.12335\n#&gt; 4 I(exper^2)      -0.00224    -0.00083  -0.00141 -0.00086 -0.00189\n#&gt; 5      kids5      -0.63321     0.01566  -0.64887  0.00000 -0.86833\n#&gt; 6    kids618       0.02626    -0.00065   0.02691  0.00000  0.03600\n#&gt; 7   nwifeinc      -0.00877     0.00022  -0.00898  0.00000 -0.01202\nなお、heckitmfx() 関数の出力の各列は次の値に対応しています。\n\nunconditional： 条件なしの平均限界効果 \\(\\overline{ME}(\\boldsymbol{x}_j)\\)。\nconditional： 条件付き平均限界効果 \\(\\overline{ME}(\\boldsymbol{x}_j | Y_{1i}^* \\ge 0)\\)。\nselection： 間接効果の平均値 \\(e_{II} = \\gamma_j \\lambda(\\boldsymbol{Z}_i^\\mathsf{T}\\boldsymbol{\\gamma})\\)\nbeta：賃金関数の回帰係数の推定値 \\(\\hat{\\boldsymbol{\\beta}}\\)\ngamma：就業決定関数の回帰係数の推定値 \\(\\hat{\\boldsymbol{\\gamma}}\\)\n\n\n\nExample 1.3 (ブートストラップ法を使った限界効果の標準誤差の推定) ここでは 例題 1.2 で推定したタイプIIトービットモデルの限界効果について、ブートストラップ法を使った標準誤差の推定と検定を試みたいと思います。まず、 例題 1.1 で実装したモデル推定し、例題 1.2 で実装した heckitmfx() 関数で限界効果を推定するまでの操作を、ひとまとめにしたラッパー関数を定義します。\nest_heckit_mfx &lt;- function(data){\n  mod &lt;- sampleSelection::heckit(\n    selection = lfp ~ educ + exper + I(exper^2) + nwifeinc + age + kids5 + kids618, # 就業決定関数\n    outcome =  lwage ~ educ + exper + I(exper^2),                                      # 賃金関数\n    data = data,\n    method = \"2step\"\n  )\n  res &lt;- heckitmfx(mod, newdata = data)  \n  return(res)\n}\n次に、slice_sample() 関数で復元抽出を行い、反復回数を1,000回でブートストラップ法を実行します。\nset.seed(123)\ntictoc::tic() # 参考までに実行時間を計測しておきます。\n\nheckitmfx_with_boot &lt;- map(\n  .x = 1:1000, \n  .f = \\(x) est_heckit_mfx(Mroz87 |&gt; slice_sample(prop = 1, replace = TRUE))\n  ) |&gt;\n  bind_rows(.id = \"Iteration\")\n\ntictoc::toc()\n#&gt; 26.45 sec elapsed\nここでは ggdist::stat_pointinterval() 関数を使ってブートストラップ統計量の分布を可視化してみましょう。\n\nheckitmfx_with_boot |&gt; \n  select(Iteration:selection) |&gt; \n  pivot_longer(unconditional:selection, names_to = \"type\", values_to = \"estimate\") |&gt; \n  ggplot(aes(x = estimate, y = term)) +\n  geom_vline(xintercept = 0, color = \"gray60\", linetype = 2) +\n  ggdist::stat_pointinterval(\n    color = my_color, alpha = 0.7, \n    point_interval = \"mean_qi\", # `summarise_boot` と一致するように点推定を平均値とします。\n    .width = c(0.95, 0.99)\n    ) + \n  facet_wrap(~type)\n\n\n\n\n\n\n\n\n次に、heckitmfx() で得られる3種類の限界効果について、ブートストラップ統計量を集計して、それぞれ標準誤差分位点法による\\(p\\)-値を計算します。なお、ブートストラップ法やブートストラップ法での信頼区間と\\(p\\)-値の計算方法については末石(2015, p. 140)、Efron & Hastie(2016)、Taddy(2019)および Bodory et al.(Bodory et al., 2020, p. 16)を参照してください。\n\nsummarise_boot &lt;- function(res_boot, var){\n  res_boot |&gt; \n    summarise(\n    type = var,\n    estimate = mean(.data[[var]]),\n    std.error = sd(.data[[var]]),                                        # 標準誤差\n    p.value = 2 * pmin(mean(.data[[var]] &lt;= 0), mean(.data[[var]] &gt; 0)), # 分位点法によるp-値\n    .lower = quantile(.data[[var]], 0.025),\n    .upper = quantile(.data[[var]], 0.975),\n    .by = term\n  )\n}\n\nsummary_boot &lt;- map(\n  .x = c(\"unconditional\", \"conditional\", \"selection\"), \n  .f = \\(x) summarise_boot(heckitmfx_with_boot, x)\n  ) |&gt; \n  bind_rows()\n\n　最後に推定結果を比較しやすいように、texreg::screenreg() を模したフォーマットに変換してみましょう。推定結果を比較すると、年齢 Age や Crossbuying などように一貫して限界効果が統計的に有意な変数がある一方で、性別 Sex については総効果 dydx では有意でなくても間接効果は有意であるという結果になっていることが興味深く感じられます（表 1.1）。\n\n\n\n表 1.1: ブートストラップ法による推定結果\n\n\n\n\n\n\nterm\n\n\nunconditional\n\n\nconditional\n\n\nselection\n\n\n\n\n\n\nage\n\n\n-0.0392***(0.0086)\n\n\n0.0010 (0.0046)\n\n\n-0.0402***(0.0069)\n\n\n\n\neduc\n\n\n0.2059***(0.0251)\n\n\n0.1060***(0.0141)\n\n\n0.0999***(0.0203)\n\n\n\n\nexper\n\n\n0.1350***(0.0214)\n\n\n0.0417**(0.0152)\n\n\n0.0933***(0.0159)\n\n\n\n\nI(exper^2)\n\n\n-0.0022***(0.0006)\n\n\n-0.0008*(0.0004)\n\n\n-0.0014**(0.0005)\n\n\n\n\nkids5\n\n\n-0.6424***(0.1248)\n\n\n0.0168 (0.0756)\n\n\n-0.6592***(0.0996)\n\n\n\n\nkids618\n\n\n0.0276 (0.0344)\n\n\n-0.0008 (0.0050)\n\n\n0.0284 (0.0350)\n\n\n\n\nnwifeinc\n\n\n-0.0091*(0.0040)\n\n\n0.0003 (0.0012)\n\n\n-0.0094*(0.0040)\n\n\n\n\n\n\nNote: \n\n\n\n\n 括弧内はブートストラップ法による標準誤差\n\n\n\n\n Signif. codes: 0 ’***’ 0.001 ’**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n\n\n\n\n\n\n\n\n\n\n\nBodory, Hugo, Lorenzo Camponovo, Martin Huber, and Michael Lechner. (2020). The finite sample performance of inference methods for propensity score matching and weighting estimators. Journal of Business & Economic Statistics, 38(1), 183–200.\n\n\nEfron, Bradley, and Trevor Hastie. (2016). Computer age statistical inference. Cambridge University Press. https://web.stanford.edu/~hastie/CASI/ Institute of mathematical statistics monographs\n\n\nHoffmann, Rodolfo, and Ana Lucia Kassouf. (2005). Deriving conditional and unconditional marginal effects in log earnings equations estimated by heckman’s procedure. Applied Economics, 37(11), 1303–1311.\n\n\nTaddy, Matt. (2019). Business data science: Combining machine learning and economics to optimize, automate, and accelerate business decisions. McGraw-Hill Education. https://www.oreilly.com/library/view/business-data-science/9781260452785/ 上杉隼人, 井上毅郎〔訳〕(2020)『ビジネスデータサイエンスの教科書』すばる舎\n\n\nダハナ・ウィラワン ドニ, and 勝又壮太郎. (2023). 『Rによるマーケティング・データ分析: 基礎から応用まで (ライブラリ データ分析への招待 4)』. 新世社.\n\n\n大森義明, and 永瀬伸子. (2021). 『労働経済学をつかむ』. 有斐閣.\n\n\n川口大司. (2017). 『労働経済学 – 理論と実証をつなぐ』. 有斐閣.\n\n\n春山鉄源. (2023). Pythonで学ぶ入門計量経済学. https://py4etrics.github.io/index.html\n\n\n末石直也. (2015). 『計量経済学：ミクロデータ分析へのいざない』. 日本評論社.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>タイプIIトービットモデル</span>"
    ]
  },
  {
    "objectID": "90-references.html",
    "href": "90-references.html",
    "title": "References",
    "section": "",
    "text": "Bodory, Hugo, Lorenzo Camponovo, Martin Huber, and Michael Lechner.\n(2020). The finite sample performance of inference methods for\npropensity score matching and weighting estimators. Journal of\nBusiness & Economic Statistics, 38(1), 183–200.\n\n\nEfron, Bradley, and Trevor Hastie. (2016). Computer age statistical\ninference. Cambridge University Press. https://web.stanford.edu/~hastie/CASI/\nInstitute of mathematical statistics monographs\n\n\nHoffmann, Rodolfo, and Ana Lucia Kassouf. (2005). Deriving conditional\nand unconditional marginal effects in log earnings equations estimated\nby heckman’s procedure. Applied Economics, 37(11),\n1303–1311.\n\n\nTaddy, Matt. (2019). Business data science: Combining machine\nlearning and economics to optimize, automate, and accelerate business\ndecisions. McGraw-Hill Education. https://www.oreilly.com/library/view/business-data-science/9781260452785/\n上杉隼人,\n井上毅郎〔訳〕(2020)『ビジネスデータサイエンスの教科書』すばる舎\n\n\nダハナ・ウィラワン ドニ, and 勝又壮太郎. (2023).\n『Rによるマーケティング・データ分析: 基礎から応用まで (ライブラリ\nデータ分析への招待 4)』. 新世社.\n\n\n大森義明, and 永瀬伸子. (2021). 『労働経済学をつかむ』. 有斐閣.\n\n\n川口大司. (2017). 『労働経済学 – 理論と実証をつなぐ』. 有斐閣.\n\n\n春山鉄源. (2023). Pythonで学ぶ入門計量経済学. https://py4etrics.github.io/index.html\n\n\n末石直也. (2015). 『計量経済学：ミクロデータ分析へのいざない』.\n日本評論社.",
    "crumbs": [
      "References"
    ]
  }
]